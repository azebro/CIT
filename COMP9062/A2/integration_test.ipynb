{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/11/08 02:00:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------                                     \n",
      "Time: 2020-11-08 02:00:25\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:00:30\n",
      "-------------------------------------------\n",
      "('09', 50.0)\n",
      "('08', 75.0)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:00:35\n",
      "-------------------------------------------\n",
      "('09', 45.0)\n",
      "('08', 150.0)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:00:40\n",
      "-------------------------------------------\n",
      "('09', 100.0)\n",
      "('08', 350.0)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:00:45\n",
      "-------------------------------------------\n",
      "\n",
      "20/11/08 02:00:48 WARN BatchedWriteAheadLog: BatchedWriteAheadLog Writer queue interrupted.\n"
     ]
    }
   ],
   "source": [
    "! python3 A02_ex1_spark_streaming.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/11/08 02:00:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------- Streaming Context is defined -----------------------\n",
      "-------------------------------------------                                     \n",
      "Time: 2020-11-08 02:01:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:01:05\n",
      "-------------------------------------------\n",
      "('2013-01-01', ['40', '41'])\n",
      "('2013-01-02', ['50', '55', '60'])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:01:10\n",
      "-------------------------------------------\n",
      "('2013-01-04', ['50', '55'])\n",
      "('2013-01-03', ['40'])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:01:15\n",
      "-------------------------------------------\n",
      "('2013-01-06', ['50'])\n",
      "('2013-01-05', ['40', '41', '42'])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:01:20\n",
      "-------------------------------------------\n",
      "('2013-01-07', ['40'])\n",
      "('2013-01-08', ['50', '60'])\n",
      "\n",
      "20/11/08 02:01:24 WARN BatchedWriteAheadLog: BatchedWriteAheadLog Writer queue interrupted.\n"
     ]
    }
   ],
   "source": [
    "! python3 A02_ex2_spark_streaming.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/11/08 02:10:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "20/11/08 02:10:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:10:25\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:10:30\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:10:35\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:10:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:10:45\n",
      "-------------------------------------------\n",
      "\n",
      "20/11/08 02:10:46 WARN BatchedWriteAheadLog: BatchedWriteAheadLog Writer queue interrupted.\n"
     ]
    }
   ],
   "source": [
    "! python3 A02_ex3_spark_streaming.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/11/08 02:11:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "20/11/08 02:11:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------                                     \n",
      "Time: 2020-11-08 02:11:35\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:11:40\n",
      "-------------------------------------------\n",
      "('1935', ('2013-01-10 09:02:00', 121))\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:11:45\n",
      "-------------------------------------------\n",
      "('1935', ('2013-01-10 09:02:00', 121))\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:11:50\n",
      "-------------------------------------------\n",
      "('1935', ('2013-01-10 09:02:00', 121))\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2020-11-08 02:11:55\n",
      "-------------------------------------------\n",
      "('1935', ('2013-01-10 09:02:00', 121))\n",
      "\n",
      "20/11/08 02:11:55 WARN BatchedWriteAheadLog: BatchedWriteAheadLog Writer queue interrupted.\n"
     ]
    }
   ],
   "source": [
    "! python3 A02_ex4_spark_streaming.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
