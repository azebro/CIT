{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Assignement 2 - Part A\n",
    "\n",
    "#### R00183247 - Adam Zebrowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 128, 128, 3) (1020,)\n",
      "(340, 128, 128, 3) (340,)\n"
     ]
    }
   ],
   "source": [
    "def loadDataH5():\n",
    "    with h5py.File('data/data1.h5','r') as hf: \n",
    "        trainX = np.array(hf.get('trainX')) \n",
    "        trainY = np.array(hf.get('trainY')) \n",
    "        valX = np.array(hf.get('valX')) \n",
    "        valY = np.array(hf.get('valY')) \n",
    "        print (trainX.shape,trainY.shape) \n",
    "        print (valX.shape,valY.shape)\n",
    "    return trainX, trainY, valX, valY\n",
    "trainX, trainY, testX, testY = loadDataH5()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 25\n",
    "WIDTH = trainX.shape[2]\n",
    "HEIGHT = trainX.shape[1]\n",
    "CLASSES = 17\n",
    "DEPTH = trainX.shape[3]\n",
    "BATCH_SIZE = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualiseOutput(history):\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Min Val Loss: \", min(history.history['val_loss']))\n",
    "    print(\"Max Val Accuracy: \", max(history.history['val_accuracy']))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "   \n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.xlabel('Epoch #')\n",
    "    plt.legend(['train loss', 'val loss', 'train acc', 'val acc'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def executeModel(model):\n",
    "    opt = keras.optimizers.SGD(lr=0.01)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    h = model.fit(trainX, trainY, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_split=0.1, verbose=0)\n",
    "    visualiseOutput(h)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part i\n",
    "Implement a baseline CNN, which contains just a single convolutional layer, single pooling layer, fully connected layer and softmax layer.\n",
    "Increase the number of layers in your CNN (the number of convolutional and pooling layers). \n",
    "You should implement at least three different CNN configurations (not including the baseline). In your report show the impact on the validation and training accuracy/loss values (inclusive of the baseline case). \n",
    "Compare and contrast the performance of your models in your report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def singleLayers():\n",
    "    inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\", input_shape=inputShape, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1000,activation='relu'))\n",
    "    model.add(keras.layers.Dense(CLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = singleLayers()\n",
    "executeModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeper1():\n",
    "    inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\", input_shape=inputShape, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1000,activation='relu'))\n",
    "    model.add(keras.layers.Dense(CLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeper1()\n",
    "executeModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeper2():\n",
    "    inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), padding=\"same\", input_shape=inputShape, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), padding=\"same\", input_shape=inputShape, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1000,activation='relu'))\n",
    "    model.add(keras.layers.Dense(CLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeper2()\n",
    "executeModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeper3():\n",
    "    inputShape = ()\n",
    "    #mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    #with mirrored_strategy.scope():\n",
    "    model = keras.models.Sequential()\n",
    "    inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), padding=\"same\", input_shape=inputShape, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(512, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(1024, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(512,activation='relu'))\n",
    "    model.add(keras.layers.Dense(CLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeper3()\n",
    "executeModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeAugmentedModel(model, generator):\n",
    "    trainGenerator = generator.flow(trainX, trainY, batch_size= BATCH_SIZE)\n",
    "    opt = keras.optimizers.SGD(lr=0.01)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    h = model.fit(trainGenerator, \n",
    "                        validation_data=(testX, testY), \n",
    "                        steps_per_epoch=len(trainX) / BATCH_SIZE, \n",
    "                        epochs = NUM_EPOCHS, verbose=0)\n",
    "    visualiseOutput(h)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=90,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    "    #channel_shift_range=150.0,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #brightness_range=(0.1, 0.9)\n",
    "    )\n",
    "data_gen_args = dict(\n",
    "        rotation_range=90,\n",
    "        zoom_range=0.2,\n",
    "        #shear_range=0.3,\n",
    "        width_shift_range=0.3, \n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeper2()\n",
    "executeAugmentedModel(model, trainDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeper3()\n",
    "executeAugmentedModel(model, trainDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=90,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    #brightness_range=(0.1, 0.9)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeper2()\n",
    "executeAugmentedModel(model, trainDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeper3()\n",
    "executeAugmentedModel(model, trainDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
