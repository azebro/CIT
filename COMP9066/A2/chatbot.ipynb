{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hl5dTGwvsSb",
        "outputId": "aeac0383-95e9-4a7d-e769-a3139b6b3cb0"
      },
      "source": [
        "%tensorflow_version 1.x\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01yH3BjR1Nof",
        "outputId": "a6e109db-6c07-489e-f33b-325b4ca51051"
      },
      "source": [
        "!curl --header 'Host: raw.githubusercontent.com' --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://github.com/marsan-ma/chat_corpus/blob/master/twitter_en.txt.gz' --header 'Upgrade-Insecure-Requests: 1' 'https://raw.githubusercontent.com/marsan-ma/chat_corpus/master/twitter_en.txt.gz' --output 'twitter_en.txt.gz'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 20.3M  100 20.3M    0     0  16.9M      0  0:00:01  0:00:01 --:--:-- 16.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nzq5SlFvyiF",
        "outputId": "5cff45ed-c035-4ca5-9902-b316f9683f7c"
      },
      "source": [
        "!curl --header 'Host: www.cs.cornell.edu' --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --header 'Upgrade-Insecure-Requests: 1' 'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip' --output 'cornell_movie_dialogs_corpus.zip'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 9684k  100 9684k    0     0  12.0M      0 --:--:-- --:--:-- --:--:-- 12.0M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhZ2GeS5wFXY"
      },
      "source": [
        "#!curl --header 'Host: www.cs.cornell.edu' --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --header 'Upgrade-Insecure-Requests: 1' 'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip' --output 'cornell_movie_dialogs_corpus.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "Un9kIUmTwUfk",
        "outputId": "584c6f86-5040-41c5-84d3-fce6746c902a"
      },
      "source": [
        "!pip install patool\r\n",
        "import patoolib\r\n",
        "\r\n",
        "patoolib.extract_archive('/content/twitter_en.txt.gz')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 10.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "patool: Extracting /content/twitter_en.txt.gz ...\n",
            "patool: running /usr/bin/7z e -o./Unpack_itvx4c0x -- /content/twitter_en.txt.gz\n",
            "patool: ... /content/twitter_en.txt.gz extracted to `chat.txt'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'chat.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "bnt8QCjuApEi",
        "outputId": "020c4914-f500-4ae1-db1f-ca7a6ae24325"
      },
      "source": [
        "patoolib.extract_archive('/content/cornell_movie_dialogs_corpus.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patool: Extracting /content/cornell_movie_dialogs_corpus.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack__oxcv3hf -- /content/cornell_movie_dialogs_corpus.zip\n",
            "patool: ... /content/cornell_movie_dialogs_corpus.zip extracted to `cornell_movie_dialogs_corpus' (multiple files in root).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cornell_movie_dialogs_corpus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgeMpVWwQwZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85d22fa-0f46-4d93-a127-deaf23925354"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxAZVtoa_fqq",
        "outputId": "28f8455d-ac7e-4fcd-ae7a-4aab7f50e48c"
      },
      "source": [
        "!pip install demoji"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting demoji\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6a/34379abe01c9c36fe9fddc4181dd935332e7d0159ec3fae76f712e49bcea/demoji-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.23.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
            "Installing collected packages: colorama, demoji\n",
            "Successfully installed colorama-0.4.4 demoji-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKnq-IMDwWGv",
        "outputId": "df475653-d7c8-4c70-e7ca-1f7fb498d1bd"
      },
      "source": [
        "!python3 data.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mDownloading emoji data ...\u001b[0m\n",
            "\u001b[32m... OK\u001b[0m (Got response in 0.16 seconds)\n",
            "\u001b[33mWriting emoji data to /root/.demoji/codes.json ...\u001b[0m\n",
            "\u001b[32m... OK\u001b[0m\n",
            "Preparing raw data into train set and test set ...\n",
            "chat.txt\n",
            "bre takin shots\n",
            "['accelerate operation in . best response for any action pakistan and army .', 'bre takin shots', 'nunez is a tough customer . steals second takes third on e2 .', 'hillary had nothing to do with sid blumenthal other than her slush fund paying him 10k month while using him as a shadow intel source .', 'it s a genuine evil and you will be first against the wall in the nuremberg trials that result from this movie .', 'wow this is such a gorgeous photo . what did you use to take it ?', 'besides if trump say his condolences it won t sound genuine ex dwayne wade cousin it will sound all political and petty', 'drunken ruggles in the cafe is one of the weirdest comedy scenes i can think of . in fact that whole movie is weird .', 'thinks you re mr . moon s son !', 'you think so ? a lot girls been fucking with it just not the right ones lmfao but i m thinking its time for the new cut']\n",
            "['while accelerating corruption schemes before next topi wala gets the charge', 'just standing up for my friends yo i figured i d take it for them', 'with a bad back andy ! miss duffy but love eduardo too ! ! !', 'such dishonesty is unimaginable !', 'what was vibe at p amp i ? at packed premiere w kids it was like muppet theatre place went nuts applauding .', 'on behalf of whit thank you ! ! he uses a canon rebel t6i', 'nothing about trump and his tax returns', 'that s one of the things i love about it !', 'i m okay with that . it had nothing to do with a bright orange astros jersey i was wearing', 'idk how females fuck with this', 'u gotta love his dad', 'after those takeaways ! bet they re competing for who gets the next one ! !', 'i thought you was gonna let me slide', 'you talking about the brand ambassador of watsapp ?', 'bay club or equinox ?']\n",
            "len of dialouges 16249\n",
            "movie_lines.txt\n",
            "Preparing data to be model-ready ...\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ubub-Oe4N2b"
      },
      "source": [
        "#!rm -r /content/processed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS74ublLw0z_",
        "outputId": "b8e2098b-8260-41e9-daed-76e793e61b03"
      },
      "source": [
        "!python chatbot.py --mode train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n",
            "\u001b[33mDownloading emoji data ...\u001b[0m\n",
            "\u001b[32m... OK\u001b[0m (Got response in 0.13 seconds)\n",
            "\u001b[33mWriting emoji data to /root/.demoji/codes.json ...\u001b[0m\n",
            "\u001b[32m... OK\u001b[0m\n",
            "Data ready!\n",
            "Bucketing conversation number 9999\n",
            "Bucketing conversation number 19999\n",
            "Bucketing conversation number 9999\n",
            "Bucketing conversation number 19999\n",
            "Bucketing conversation number 29999\n",
            "Bucketing conversation number 39999\n",
            "Bucketing conversation number 49999\n",
            "Bucketing conversation number 59999\n",
            "Bucketing conversation number 69999\n",
            "Bucketing conversation number 79999\n",
            "Bucketing conversation number 89999\n",
            "Bucketing conversation number 99999\n",
            "Bucketing conversation number 109999\n",
            "Bucketing conversation number 119999\n",
            "Bucketing conversation number 129999\n",
            "Bucketing conversation number 139999\n",
            "Bucketing conversation number 149999\n",
            "Bucketing conversation number 159999\n",
            "Bucketing conversation number 169999\n",
            "Bucketing conversation number 179999\n",
            "Bucketing conversation number 189999\n",
            "Bucketing conversation number 199999\n",
            "Bucketing conversation number 209999\n",
            "Bucketing conversation number 219999\n",
            "Bucketing conversation number 229999\n",
            "Bucketing conversation number 239999\n",
            "Bucketing conversation number 249999\n",
            "Bucketing conversation number 259999\n",
            "Bucketing conversation number 269999\n",
            "Bucketing conversation number 279999\n",
            "Bucketing conversation number 289999\n",
            "Bucketing conversation number 299999\n",
            "Bucketing conversation number 309999\n",
            "Bucketing conversation number 319999\n",
            "Bucketing conversation number 329999\n",
            "Bucketing conversation number 339999\n",
            "Bucketing conversation number 349999\n",
            "Bucketing conversation number 359999\n",
            "Bucketing conversation number 369999\n",
            "Bucketing conversation number 379999\n",
            "Bucketing conversation number 389999\n",
            "Bucketing conversation number 399999\n",
            "Bucketing conversation number 409999\n",
            "Bucketing conversation number 419999\n",
            "Bucketing conversation number 429999\n",
            "Bucketing conversation number 439999\n",
            "Bucketing conversation number 449999\n",
            "Bucketing conversation number 459999\n",
            "Bucketing conversation number 469999\n",
            "Bucketing conversation number 479999\n",
            "Bucketing conversation number 489999\n",
            "Bucketing conversation number 499999\n",
            "Bucketing conversation number 509999\n",
            "Bucketing conversation number 519999\n",
            "Bucketing conversation number 529999\n",
            "Bucketing conversation number 539999\n",
            "Bucketing conversation number 549999\n",
            "Bucketing conversation number 559999\n",
            "Bucketing conversation number 569999\n",
            "Bucketing conversation number 579999\n",
            "Bucketing conversation number 589999\n",
            "Number of samples in each bucket:\n",
            " [92000, 94482, 104372, 226433, 40536]\n",
            "Bucket scale:\n",
            " [0.16492686748305466, 0.3343031750214674, 0.5214091208143085, 0.9273317880402924, 1.0]\n",
            "Initialize new model\n",
            "Create placeholders\n",
            "WARNING:tensorflow:From /content/model.py:22: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Create inference\n",
            "WARNING:tensorflow:From /content/model.py:36: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/model.py:50: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/model.py:51: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
            "Creating loss... \n",
            "It might take a couple of minutes depending on how many buckets you have.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/legacy_seq2seq/python/ops/seq2seq.py:859: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Time: 21.169193029403687\n",
            "Create optimizer... \n",
            "It might take a couple of minutes depending on how many buckets you have.\n",
            "WARNING:tensorflow:From /content/model.py:95: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/model.py:99: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/model.py:100: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Creating opt for bucket 0 took 5.806444883346558 seconds\n",
            "Creating opt for bucket 1 took 7.429203510284424 seconds\n",
            "Creating opt for bucket 2 took 9.985529661178589 seconds\n",
            "Creating opt for bucket 3 took 16.07873034477234 seconds\n",
            "Creating opt for bucket 4 took 18.284971952438354 seconds\n",
            "WARNING:tensorflow:From chatbot.py:132: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From chatbot.py:134: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Running session\n",
            "WARNING:tensorflow:From chatbot.py:136: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "Initializing fresh parameters for the Chatbot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ls37uY3Km5s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7roZ50KdxJ65"
      },
      "source": [
        "!python chatbot.py --mode chat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EdrLe4heXMq"
      },
      "source": [
        "#!ls /content/checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJCUGotritWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e87cd5-b62b-4e58-da25-df2293ba2e25"
      },
      "source": [
        "!zip -r /content/file.zip  /content/processed"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/processed/ (stored 0%)\n",
            "  adding: content/processed/test_ids.dec (deflated 62%)\n",
            "  adding: content/processed/vocab.dec (deflated 51%)\n",
            "  adding: content/processed/train.dec (deflated 61%)\n",
            "  adding: content/processed/train.enc (deflated 62%)\n",
            "  adding: content/processed/test.enc (deflated 60%)\n",
            "  adding: content/processed/train_ids.dec (deflated 63%)\n",
            "  adding: content/processed/test_ids.enc (deflated 59%)\n",
            "  adding: content/processed/test.dec (deflated 60%)\n",
            "  adding: content/processed/vocab.enc (deflated 51%)\n",
            "  adding: content/processed/train_ids.enc (deflated 61%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL67_y7nmGZ4"
      },
      "source": [
        "#!zip -r /content/preprocessed.zip /content/processed"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}